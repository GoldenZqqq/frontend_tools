<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Big File Upload</title>
  </head>
  <body>
    <input type="file" />

    <script src="./spark-md5.js"></script>
    <!-- 一般不会放到主线程，一般使用web worker另开一个线程避免浏览器卡死 -->
    <script>
      const inp = document.querySelector("input")
      inp.onchange = async e => {
        const file = inp.files[0]
        if (!file) return
        // const piece = file.slice(0, 100) // 取文件的0个字节到100个字节
        const chunks = createChunks(file, 10 * 1024 * 1024)
        const result = await hash(chunks)
        console.log(result)
      }

      // 计算文件的hash值 不能一次性计算全部 使用分块计算
      function hash(chunks) {
        return new Promise(resolve => {
          const spark = new SparkMD5()
          function _read(i) {
            if (i >= chunks.length) {
              resolve(spark.end())
              return // 读取完成
            }
            const blob = chunks[i]
            const reader = new FileReader()
            reader.onload = e => {
              const bytes = e.target.result // 读取到的字节数组
              spark.append(bytes)
              _read(i + 1)
            }
            reader.readAsArrayBuffer(blob)
          }
          _read(0)
        })
      }

      // 创建分片
      function createChunks(file, chunkSize) {
        const result = []
        for (let i = 0; i < file.size; i += chunkSize) {
          result.push(file.slice(i, i + chunkSize))
        }
        return result
      }
    </script>
  </body>
</html>
